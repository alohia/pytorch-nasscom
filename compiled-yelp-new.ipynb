{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tqdm\n",
    "import random\n",
    "import torch\n",
    "random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.autograd as autograd\n",
    "import os\n",
    "import pickle\n",
    "import sklearn.metrics\n",
    "from tqdm import tqdm_notebook as tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "#try cont_lamb=2*(3e-4) and selec_lamb=3e-4, working - sl = 0.001, cl = 2*0.001\n",
    "args = Namespace(aspect='overall', batch_size=256, class_balance=False,\n",
    "                 continuity_lambda=0.005, cuda=True,\n",
    "                 debug_mode=False, dropout=0.2, embedding='glove', embedding_dim=300,\n",
    "                 epochs=20, filter_num=100, filters=[3, 4, 5], get_rationales=True,\n",
    "                 gumbel_decay=1e-05, gumbel_temprature=1, hidden_dim=100,\n",
    "                 init_lr=0.002, model_form='cnn', num_class=5, num_gpus=1,\n",
    "                 num_layers=1, num_workers=0, objective='cross_entropy', patience=5,\n",
    "                 results_path='logs/demo_run.results', save_dir='snapshot',\n",
    "                 selection_lambda=0.0005, snapshot=None, test=True,\n",
    "                 train=True, tuning_metric='loss', use_as_tagger=False, weight_decay=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = vars(args)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "args_dict['continuity_lambda'] = 2 * args_dict['selection_lambda']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def getGloveEmbedding():\n",
    "    embedding_path='data/embeddings/glove.6B/glove.6B.300d.txt'\n",
    "    lines = []\n",
    "    with open(embedding_path) as file:\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "    embedding_tensor = []\n",
    "    word_to_indx = {}\n",
    "    for indx, l in enumerate(lines):\n",
    "        word, emb = l.split()[0], l.split()[1:]\n",
    "        if not len(emb) == 300:\n",
    "            continue\n",
    "        vector = [float(x) for x in emb]\n",
    "        if indx == 0:\n",
    "            embedding_tensor.append(np.zeros(len(vector)))\n",
    "        embedding_tensor.append(vector)\n",
    "        word_to_indx[word] = indx+1\n",
    "    embedding_tensor = np.array(embedding_tensor, dtype=np.float32)\n",
    "    return embedding_tensor, word_to_indx"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "embeddings, word_to_indx = getGloveEmbedding()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.save('embed.npy', embeddings)\n",
    "pickle.dump(word_to_indx, open('stoi.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('embed.npy')\n",
    "word_to_indx = pickle.load(open('stoi.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_tensor(text_arr, word_to_indx, max_length):\n",
    "    '''\n",
    "    -text_arr: array of word tokens\n",
    "    -word_to_indx: mapping of word -> index\n",
    "    -max length of return tokens\n",
    "\n",
    "    returns tensor of same size as text with each words corresponding index\n",
    "    '''\n",
    "    nil_indx = 0\n",
    "    text_indx = [ word_to_indx[x] if x in word_to_indx else nil_indx for x in text_arr][:max_length]\n",
    "    if len(text_indx) < max_length:\n",
    "        text_indx.extend( [nil_indx for _ in range(max_length - len(text_indx))])\n",
    "\n",
    "    x =  torch.LongTensor([text_indx])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta\n",
    "\n",
    "TRAIN_ONLY_ERR_MSG = \"{} only supported for train dataset! Instead saw {}\"\n",
    "\n",
    "class AbstractDataset(data.Dataset):\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        sample = self.dataset[index]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpDataset(AbstractDataset):\n",
    "\n",
    "    def __init__(self, args, word_to_indx, name, df, max_length=100):\n",
    "        self.args = args\n",
    "        self.name = name\n",
    "        self.dataset = []\n",
    "        self.word_to_indx  = word_to_indx\n",
    "        self.max_length = max_length\n",
    "        self.class_balance = {}\n",
    "        self.df = df\n",
    "\n",
    "        if name in ['train', 'dev']:\n",
    "            data = self.preprocess_data(self.df)\n",
    "            random.shuffle(data)\n",
    "            num_train = int(len(data)*.8)\n",
    "            if name == 'train':\n",
    "                data = data[:num_train]\n",
    "            else:\n",
    "                data = data[num_train:]\n",
    "        else:\n",
    "            data = self.preprocess_data(self.df)\n",
    "\n",
    "        for indx, _sample in tn(enumerate(data)):\n",
    "            sample = self.processLine(_sample)\n",
    "\n",
    "            if not sample['y'] in self.class_balance:\n",
    "                self.class_balance[ sample['y'] ] = 0\n",
    "            self.class_balance[ sample['y'] ] += 1\n",
    "            self.dataset.append(sample)\n",
    "\n",
    "        print (\"Class balance\", self.class_balance)\n",
    "\n",
    "    ## Convert one line from yelp dataset to {Text, Tensor, Labels}\n",
    "    def processLine(self, row):\n",
    "        text, label = row\n",
    "        text = \" \".join(text.split()[:self.max_length])\n",
    "        x =  get_indices_tensor(text.split(), self.word_to_indx, self.max_length)\n",
    "        sample = {'text':text,'x':x, 'y':label}\n",
    "        return sample\n",
    "    \n",
    "    def preprocess_data(self, df):\n",
    "        processed_data = []\n",
    "        for indx, sample in enumerate(df.text.values):\n",
    "            text, label = sample, df['y'][indx]\n",
    "#             label_name = data['target_names'][label]\n",
    "            text = re.sub('\\W+', ' ', text).lower().strip()\n",
    "            processed_data.append( (text, label) )\n",
    "        return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df, tst_df = pd.read_csv('yelp_review_full_csv/yelp_train.csv'), pd.read_csv('yelp_review_full_csv/yelp_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df['y'] = trn_df['y'] - 1\n",
    "tst_df['y'] = tst_df['y'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(args, word_to_indx, trn_df, tst_df):\n",
    "    train = YelpDataset(args, word_to_indx, 'train', trn_df)\n",
    "    dev = YelpDataset(args, word_to_indx, 'dev', trn_df)\n",
    "    test = YelpDataset(args, word_to_indx, 'test', tst_df)\n",
    "    return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e399e8ab5838444eb8eccb50582e17cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class balance {1: 7963, 3: 8014, 0: 7975, 2: 8013, 4: 8035}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334ef193bf204c928b12cc6a588a71b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class balance {4: 2019, 0: 2014, 1: 1995, 3: 1970, 2: 2002}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb84a58f18348e7b8788fd0dd9b4f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class balance {2: 2000, 4: 2000, 1: 2000, 0: 2000, 3: 2000}\n"
     ]
    }
   ],
   "source": [
    "train_data, dev_data, test_data = get_dataset(args_dict, word_to_indx, trn_df, tst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path_stem = args_dict['results_path'].split('/')[-1].split('.')[0]\n",
    "args_dict['model_path'] = '{}.pt'.format(os.path.join(args_dict['save_dir'], results_path_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snapshot/demo_run.pt'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_dict['model_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, args, max_pool_over_time=False):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.args = args\n",
    "        self.layers = []\n",
    "        for layer in range(args['num_layers']):\n",
    "            convs = []\n",
    "            for filt in args['filters']:\n",
    "                in_channels =  args['embedding_dim'] if layer == 0 else args['filter_num'] * len( args['filters'])\n",
    "                kernel_size = filt\n",
    "                new_conv = nn.Conv1d(in_channels=in_channels, out_channels=args['filter_num'], kernel_size=kernel_size)\n",
    "                self.add_module( 'layer_'+str(layer)+'_conv_'+str(filt), new_conv)\n",
    "                convs.append(new_conv)\n",
    "\n",
    "            self.layers.append(convs)\n",
    "\n",
    "        self.max_pool = max_pool_over_time\n",
    "\n",
    "\n",
    "\n",
    "    def _conv(self, x):\n",
    "        layer_activ = x\n",
    "        for layer in self.layers:\n",
    "            next_activ = []\n",
    "            for conv in layer:\n",
    "                left_pad = conv.kernel_size[0] - 1\n",
    "                pad_tensor_size = [d for d in layer_activ.size()]\n",
    "                pad_tensor_size[2] = left_pad\n",
    "                left_pad_tensor = torch.zeros(pad_tensor_size)\n",
    "                if self.args['cuda']:\n",
    "                    left_pad_tensor = left_pad_tensor.cuda()\n",
    "                padded_activ = torch.cat( (left_pad_tensor, layer_activ), dim=2)\n",
    "                next_activ.append( conv(padded_activ) )\n",
    "\n",
    "            # concat across channels\n",
    "            layer_activ = F.relu( torch.cat(next_activ, 1) )\n",
    "\n",
    "        return layer_activ\n",
    "\n",
    "\n",
    "    def _pool(self, relu):\n",
    "        pool = F.max_pool1d(relu, relu.size(2)).squeeze(-1)\n",
    "        return pool\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        activ = self._conv(x)\n",
    "        if self.max_pool:\n",
    "            activ =  self._pool(activ)\n",
    "        return activ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_loader(train_data, args):\n",
    "    train_loader = data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=args['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=args['num_workers'],\n",
    "        drop_last=False)\n",
    "\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dev_loader(dev_data, args):\n",
    "    dev_loader = data.DataLoader(\n",
    "        dev_data,\n",
    "        batch_size=args['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=args['num_workers'],\n",
    "        drop_last=False)\n",
    "    return dev_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rationales(mask, text):\n",
    "    if mask is None:\n",
    "        return text\n",
    "    masked_text = []\n",
    "    for i, t in enumerate(text):\n",
    "        sample_mask = list(mask.data[i])\n",
    "        original_words = t.split()\n",
    "        words = [ w if m  > .5 else \"_\" for w,m in zip(original_words, sample_mask) ]\n",
    "        masked_sample = \" \".join(words)\n",
    "        masked_text.append(masked_sample)\n",
    "    return masked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(models, args):\n",
    "    '''\n",
    "        -models: List of models (such as Generator, classif, memory, etc)\n",
    "        -args: experiment level config\n",
    "\n",
    "        returns: torch optimizer over models\n",
    "    '''\n",
    "    params = []\n",
    "    for model in models:\n",
    "        params.extend([param for param in model.parameters() if param.requires_grad])\n",
    "    return torch.optim.Adam(params, lr=args['lr'],  weight_decay=args['weight_decay'], betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hard_mask(z):\n",
    "    '''\n",
    "        -z: torch Tensor where each element probablity of element\n",
    "        being selected\n",
    "        -args: experiment level config\n",
    "\n",
    "        returns: A torch variable that is binary mask of z >= .5\n",
    "    '''\n",
    "    max_z, ind = torch.max(z, dim=-1)\n",
    "    masked = torch.ge(z, max_z.unsqueeze(-1)).float()\n",
    "    del z\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_path(model_path):\n",
    "    '''\n",
    "        -model_path: path of encoder model\n",
    "\n",
    "        returns: path of generator\n",
    "    '''\n",
    "    return '{}.gen'.format(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_softmax(input, temperature, cuda):\n",
    "    noise = torch.rand(input.size())\n",
    "    noise.add_(1e-9).log_().neg_()\n",
    "    noise.add_(1e-9).log_().neg_()\n",
    "    if cuda:\n",
    "        noise = noise.cuda()\n",
    "    x = (input + noise) / temperature\n",
    "    x = F.softmax(x.view(-1,  x.size()[-1]), dim=-1)\n",
    "    return x.view_as(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, embeddings, args):\n",
    "        super(Generator, self).__init__()\n",
    "        vocab_size, hidden_dim = embeddings.shape\n",
    "        self.embedding_layer = nn.Embedding( vocab_size, hidden_dim)\n",
    "        self.embedding_layer.weight.data = torch.from_numpy( embeddings )\n",
    "        self.embedding_layer.weight.requires_grad = False\n",
    "        self.args = args\n",
    "        self.cnn = CNN(args, max_pool_over_time = False)    \n",
    "\n",
    "        self.z_dim = 2\n",
    "\n",
    "        self.hidden = nn.Linear((len(args['filters'])* args['filter_num']), self.z_dim)\n",
    "        self.dropout = nn.Dropout(args['dropout'])\n",
    "\n",
    "\n",
    "\n",
    "    def  __z_forward(self, activ):\n",
    "        '''\n",
    "            Returns prob of each token being selected\n",
    "        '''\n",
    "        activ = activ.transpose(1,2)\n",
    "        logits = self.hidden(activ)\n",
    "        probs = gumbel_softmax(logits, self.args['gumbel_temprature'], self.args['cuda'])\n",
    "        z = probs[:,:,1]\n",
    "        return z\n",
    "\n",
    "\n",
    "    def forward(self, x_indx):\n",
    "        '''\n",
    "            Given input x_indx of dim (batch, length), return z (batch, length) such that z\n",
    "            can act as element-wise mask on x\n",
    "        '''\n",
    "        x = self.embedding_layer(x_indx.squeeze(1))\n",
    "        if self.args['cuda']:\n",
    "            x = x.cuda()\n",
    "        x = torch.transpose(x, 1, 2) # Switch X to (Batch, Embed, Length)\n",
    "        activ = self.cnn(x)\n",
    "        \n",
    "        z = self.__z_forward(F.relu(activ))\n",
    "        mask = self.sample(z)\n",
    "        return mask, z\n",
    "\n",
    "\n",
    "    def sample(self, z):\n",
    "        '''\n",
    "            Get mask from probablites at each token. Use gumbel\n",
    "            softmax at train time, hard mask at test time\n",
    "        '''\n",
    "        mask = z\n",
    "        if self.training:\n",
    "            mask = z\n",
    "        else:\n",
    "            ## pointwise set <.5 to 0 >=.5 to 1\n",
    "            mask = get_hard_mask(z)\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def loss(self, mask, x_indx):\n",
    "        '''\n",
    "            Compute the generator specific costs, i.e selection cost, continuity cost, and global vocab cost\n",
    "        '''\n",
    "#         print(mask)\n",
    "#         print(mask.shape)\n",
    "        selection_cost = torch.mean( torch.sum(mask, dim=1) )\n",
    "        l_padded_mask =  torch.cat( [mask[:,0].unsqueeze(1), mask] , dim=1)\n",
    "        r_padded_mask =  torch.cat( [mask, mask[:,-1].unsqueeze(1)] , dim=1)\n",
    "        continuity_cost = torch.mean( torch.sum( torch.abs( l_padded_mask - r_padded_mask ) , dim=1) )\n",
    "        return selection_cost, continuity_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embeddings, args):\n",
    "        super(Encoder, self).__init__()\n",
    "        ### Encoder\n",
    "        self.args = args\n",
    "        vocab_size, hidden_dim = embeddings.shape\n",
    "        self.embedding_dim = hidden_dim\n",
    "        self.embedding_layer = nn.Embedding( vocab_size, hidden_dim)\n",
    "        self.embedding_layer.weight.data = torch.from_numpy( embeddings )\n",
    "        self.embedding_layer.weight.requires_grad = True\n",
    "        self.embedding_fc = nn.Linear( hidden_dim, hidden_dim )\n",
    "        self.embedding_bn = nn.BatchNorm1d( hidden_dim)\n",
    "\n",
    "        self.cnn = CNN(args, max_pool_over_time=True)\n",
    "        self.fc = nn.Linear( len(args['filters'])*args['filter_num'],  args['hidden_dim'])\n",
    "\n",
    "        self.dropout = nn.Dropout(args['dropout'])\n",
    "        self.hidden = nn.Linear(args['hidden_dim'], args['num_class'])\n",
    "\n",
    "    def forward(self, x_indx, mask=None):\n",
    "        '''\n",
    "            x_indx:  batch of word indices\n",
    "            mask: Mask to apply over embeddings for tao ratioanles\n",
    "        '''\n",
    "        x = self.embedding_layer(x_indx.squeeze(1))\n",
    "        if self.args['cuda']:\n",
    "            x = x.cuda()\n",
    "        if not mask is None:\n",
    "            x = x * mask.unsqueeze(-1)\n",
    "        x = F.relu( self.embedding_fc(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.transpose(x, 1, 2) # Switch X to (Batch, Embed, Length)\n",
    "        hidden = self.cnn(x)\n",
    "        hidden = F.relu( self.fc(hidden) )\n",
    "\n",
    "        hidden = self.dropout(hidden)\n",
    "        logit = self.hidden(hidden)\n",
    "        return logit, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args, embeddings, train_data):\n",
    "    gen   = Generator(embeddings, args)\n",
    "    model = Encoder(embeddings, args)\n",
    "    return gen, model\n",
    "#     else :\n",
    "#         print('\\nLoading model from [%s]...' % args.snapshot)\n",
    "#         try:\n",
    "#             gen_path = learn.get_gen_path(args.snapshot)\n",
    "#             if os.path.exists(gen_path):\n",
    "#                 gen   = torch.load(gen_path)\n",
    "#             model = torch.load(args.snapshot)\n",
    "#         except :\n",
    "#             print(\"Sorry, This snapshot doesn't exist.\"); exit()\n",
    "\n",
    "#     if args['num_gpus'] > 1:\n",
    "#         model = nn.DataParallel(model, device_ids=range(args['num_gpus']))\n",
    "\n",
    "#         if not gen is None:\n",
    "#             gen = nn.DataParallel(gen,\n",
    "#                                     device_ids=range(args['num_gpus']))\n",
    "#     return gen, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "gen, model = get_model(args_dict, embeddings, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (embedding_layer): Embedding(400001, 300)\n",
       "  (cnn): CNN(\n",
       "    (layer_0_conv_3): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (layer_0_conv_4): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (layer_0_conv_5): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (hidden): Linear(in_features=300, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding_layer): Embedding(400001, 300)\n",
       "  (embedding_fc): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (embedding_bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (cnn): CNN(\n",
       "    (layer_0_conv_3): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (layer_0_conv_4): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (layer_0_conv_5): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.2)\n",
       "  (hidden): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_epoch_stat(stat_dict, epoch_details, mode, args):\n",
    "    '''\n",
    "        Update stat_dict with details from epoch_details and create\n",
    "        log statement\n",
    "\n",
    "        - stat_dict: a dictionary of statistics lists to update\n",
    "        - epoch_details: list of statistics for a given epoch\n",
    "        - mode: train, dev or test\n",
    "        - args: model run configuration\n",
    "\n",
    "        returns:\n",
    "        -stat_dict: updated stat_dict with epoch details\n",
    "        -log_statement: log statement sumarizing new epoch\n",
    "\n",
    "    '''\n",
    "    log_statement_details = ''\n",
    "    for metric in epoch_details:\n",
    "        loss = epoch_details[metric]\n",
    "        stat_dict['{}_{}'.format(mode, metric)].append(loss)\n",
    "\n",
    "        log_statement_details += ' -{}: {}'.format(metric, loss)\n",
    "\n",
    "    log_statement = '\\n {} - {}\\n--'.format(\n",
    "        args['objective'], log_statement_details )\n",
    "\n",
    "    return stat_dict, log_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(preds, golds):\n",
    "    metrics = {}\n",
    "\n",
    "    metrics['accuracy'] = sklearn.metrics.accuracy_score(y_true=golds, y_pred=preds)\n",
    "    metrics['precision'] = sklearn.metrics.precision_score(y_true=golds, y_pred=preds, average=\"weighted\")\n",
    "    metrics['recall'] = sklearn.metrics.recall_score(y_true=golds,y_pred=preds, average=\"weighted\")\n",
    "    metrics['f1'] = sklearn.metrics.f1_score(y_true=golds,y_pred=preds, average=\"weighted\")\n",
    "\n",
    "    metrics['mse'] = \"NA\"\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_metrics_dictionary(modes):\n",
    "    '''\n",
    "    Create dictionary with empty array for each metric in each mode\n",
    "    '''\n",
    "    epoch_stats = {}\n",
    "    metrics = [\n",
    "        'loss', 'obj_loss', 'k_selection_loss',\n",
    "        'k_continuity_loss', 'accuracy', 'precision', 'recall', 'f1', 'mse']\n",
    "    for metric in metrics:\n",
    "        for mode in modes:\n",
    "            key = \"{}_{}\".format(mode, metric)\n",
    "            epoch_stats[key] = []\n",
    "\n",
    "    return epoch_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, dev_data, model, gen, args):\n",
    "    '''\n",
    "    Train model and tune on dev set. If model doesn't improve dev performance within args.patience\n",
    "    epochs, then halve the learning rate, restore the model to best and continue training.\n",
    "\n",
    "    At the end of training, the function will restore the model to best dev version.\n",
    "\n",
    "    returns epoch_stats: a dictionary of epoch level metrics for train and test\n",
    "    returns model : best model from this call to train\n",
    "    '''\n",
    "\n",
    "    if args['cuda']:\n",
    "        model = model.cuda()\n",
    "        gen = gen.cuda()\n",
    "\n",
    "    args['lr'] = args['init_lr']\n",
    "    optimizer = get_optimizer([model, gen], args)\n",
    "\n",
    "    num_epoch_sans_improvement = 0\n",
    "    epoch_stats = init_metrics_dictionary(modes=['train', 'dev'])\n",
    "    step = 0\n",
    "    tuning_key = \"dev_{}\".format(args['tuning_metric'])\n",
    "\n",
    "    train_loader = get_train_loader(train_data, args)\n",
    "    dev_loader = get_dev_loader(dev_data, args)\n",
    "\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "\n",
    "        print(\"-------------\\nEpoch {}:\\n\".format(epoch))\n",
    "        for mode, dataset, loader in [('Train', train_data, train_loader), ('Dev', dev_data, dev_loader)]:\n",
    "            train_model = mode == 'Train'\n",
    "            print('{}'.format(mode))\n",
    "            key_prefix = mode.lower()\n",
    "            epoch_details, step, _, _, _, _ = run_epoch(\n",
    "                data_loader=loader,\n",
    "                train_model=train_model,\n",
    "                model=model,\n",
    "                gen=gen,\n",
    "                optimizer=optimizer,\n",
    "                step=step,\n",
    "                args=args)\n",
    "\n",
    "            epoch_stats, log_statement = collate_epoch_stat(epoch_stats, epoch_details, key_prefix, args)\n",
    "\n",
    "            # Log  performance\n",
    "            print(log_statement)\n",
    "\n",
    "\n",
    "        # Save model if beats best dev\n",
    "        best_func = min if args['tuning_metric'] == 'loss' else max\n",
    "        if best_func(epoch_stats[tuning_key]) == epoch_stats[tuning_key][-1]:\n",
    "            num_epoch_sans_improvement = 0\n",
    "            if not os.path.isdir(args['save_dir']):\n",
    "                os.makedirs(args['save_dir'])\n",
    "            # Subtract one because epoch is 1-indexed and arr is 0-indexed\n",
    "            epoch_stats['best_epoch'] = epoch - 1\n",
    "            torch.save(model, args['model_path'])\n",
    "            torch.save(gen, get_gen_path(args['model_path']))\n",
    "        else:\n",
    "            num_epoch_sans_improvement += 1\n",
    "\n",
    "        if not train_model:\n",
    "            print('---- Best Dev {} is {:.4f} at epoch {}'.format(\n",
    "                args['tuning_metric'],\n",
    "                epoch_stats[tuning_key][epoch_stats['best_epoch']],\n",
    "                epoch_stats['best_epoch'] + 1))\n",
    "\n",
    "        if num_epoch_sans_improvement >= args['patience']:\n",
    "            print(\"Reducing learning rate\")\n",
    "            num_epoch_sans_improvement = 0\n",
    "            model.cpu()\n",
    "            gen.cpu()\n",
    "            model = torch.load(args['model_path'])\n",
    "            gen = torch.load(get_gen_path(args['model_path']))\n",
    "\n",
    "            if args['cuda']:\n",
    "                model = model.cuda()\n",
    "                gen   = gen.cuda()\n",
    "            args['lr'] *= .5\n",
    "            optimizer = get_optimizer([model, gen], args)\n",
    "\n",
    "    return epoch_stats, model, gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_data, model, gen, args):\n",
    "    '''\n",
    "    Run model on test data, and return loss, accuracy.\n",
    "    '''\n",
    "    if args['cuda']:\n",
    "        model = model.cuda()\n",
    "        gen = gen.cuda()\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data,\n",
    "        batch_size=args['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=args['num_workers'],\n",
    "        drop_last=False)\n",
    "\n",
    "    test_stats = init_metrics_dictionary(modes=['test'])\n",
    "\n",
    "    mode = 'Test'\n",
    "    train_model = False\n",
    "    key_prefix = mode.lower()\n",
    "    print(\"-------------\\nTest\")\n",
    "    epoch_details, _, losses, preds, golds, rationales = run_epoch(\n",
    "        data_loader=test_loader,\n",
    "        train_model=train_model,\n",
    "        model=model,\n",
    "        gen=gen,\n",
    "        optimizer=None,\n",
    "        step=None,\n",
    "        args=args)\n",
    "\n",
    "    test_stats, log_statement = collate_epoch_stat(test_stats, epoch_details, 'test', args)\n",
    "    test_stats['losses'] = losses\n",
    "    test_stats['preds'] = preds\n",
    "    test_stats['golds'] = golds\n",
    "    test_stats['rationales'] = rationales\n",
    "\n",
    "    print(log_statement)\n",
    "\n",
    "    return test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_loader, train_model, model, gen, optimizer, step, args):\n",
    "    '''\n",
    "    Train model for one pass of train data, and return loss, acccuracy\n",
    "    '''\n",
    "    eval_model = not train_model\n",
    "    data_iter = data_loader.__iter__()\n",
    "\n",
    "    losses = []\n",
    "    obj_losses = []\n",
    "    k_selection_losses = []\n",
    "    k_continuity_losses = []\n",
    "    preds = []\n",
    "    golds = []\n",
    "    losses = []\n",
    "    texts = []\n",
    "    rationales = []\n",
    "\n",
    "    if train_model:\n",
    "        model.train()\n",
    "        gen.train()\n",
    "    else:\n",
    "        gen.eval()\n",
    "        model.eval()\n",
    "\n",
    "    num_batches_per_epoch = len(data_iter)\n",
    "    if train_model:\n",
    "        num_batches_per_epoch = min(len(data_iter), 10000)\n",
    "\n",
    "    for _ in tn(range(num_batches_per_epoch)):\n",
    "        batch = data_iter.next()\n",
    "        if train_model:\n",
    "            step += 1\n",
    "            if  step % 100 == 0 or args['debug_mode']:\n",
    "                args['gumbel_temprature'] = max( np.exp((step+1) *-1* args['gumbel_decay']), .05)\n",
    "\n",
    "        x_indx = batch['x']\n",
    "        text = batch['text']\n",
    "        y = batch['y']\n",
    "\n",
    "        if args['cuda']:\n",
    "            x_indx, y = x_indx.cuda(), y.cuda()\n",
    "\n",
    "        if train_model:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        mask, z = gen(x_indx)\n",
    "\n",
    "        logit, _ = model(x_indx, mask=mask)\n",
    "\n",
    "        loss = get_loss(logit, y)\n",
    "        obj_loss = loss.item()\n",
    "        \n",
    "#         print('mask in run_epoch', mask)\n",
    "\n",
    "        selection_cost, continuity_cost = gen.loss(mask, x_indx)\n",
    "    \n",
    "    \n",
    "#         print('check loss')\n",
    "#         print(loss)\n",
    "        loss += args['selection_lambda'] * selection_cost\n",
    "        loss += args['continuity_lambda'] * continuity_cost\n",
    "#         print(loss)\n",
    "#         print('is it different')\n",
    "#         print(train_model)\n",
    "#         print(loss)\n",
    "#         print(loss.item())\n",
    "#         print(obj_loss)\n",
    "\n",
    "        if train_model:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "#         print(obj_loss,'\\n',selection_cost.item(),'\\n',args['selection_lambda']*selection_cost.item(),'\\n',\n",
    "#              loss.item())\n",
    "\n",
    "        k_selection_losses.append( selection_cost.item() )\n",
    "        k_continuity_losses.append( continuity_cost.item() )\n",
    "\n",
    "        obj_losses.append(obj_loss)\n",
    "        losses.append( loss.item() )\n",
    "        batch_softmax = F.softmax(logit, dim=-1).cpu()\n",
    "        preds.extend(torch.max(batch_softmax, 1)[1].view(y.size()).data.numpy())\n",
    "\n",
    "        texts.extend(text)\n",
    "        rationales.extend(get_rationales(mask, text))\n",
    "\n",
    "        golds.extend(batch['y'].numpy())\n",
    "\n",
    "\n",
    "    epoch_metrics = get_metrics(preds, golds)\n",
    "\n",
    "    epoch_stat = {\n",
    "        'loss' : np.mean(losses),\n",
    "        'obj_loss': np.mean(obj_losses)\n",
    "    }\n",
    "\n",
    "    for metric_k in epoch_metrics.keys():\n",
    "        epoch_stat[metric_k] = epoch_metrics[metric_k]\n",
    "\n",
    "    epoch_stat['k_selection_loss'] = np.mean(k_selection_losses)\n",
    "    epoch_stat['k_continuity_loss'] = np.mean(k_continuity_losses)\n",
    "\n",
    "    return epoch_stat, step, losses, preds, golds, rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(logit,y):\n",
    "    loss = F.cross_entropy(logit, y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Epoch 1:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd9aaf8ebd242e8bb299110fb32fa18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.4733342053783927 -obj_loss: 1.4338079850385144 -accuracy: 0.337525 -precision: 0.3368757121459717 -recall: 0.337525 -f1: 0.330761923920703 -mse: NA -k_selection_loss: 6.541971950773981 -k_continuity_loss: 7.251047477600681\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc44f3861dc94d53a2f1a6dd1fd33f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.4102115839719773 -obj_loss: 1.399069482088089 -accuracy: 0.4 -precision: 0.38262315103378175 -recall: 0.4 -f1: 0.3738498887971107 -mse: NA -k_selection_loss: 1.1123046875 -k_continuity_loss: 2.1171875\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Best Dev loss is 1.4102 at epoch 1\n",
      "-------------\n",
      "Epoch 2:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e789728e1c4b82919b26905a9b0933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.2515585301028695 -obj_loss: 1.2052943114262478 -accuracy: 0.475625 -precision: 0.4658971576909247 -recall: 0.475625 -f1: 0.4674891629788807 -mse: NA -k_selection_loss: 6.889938545834487 -k_continuity_loss: 8.563850293493575\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2155966d70b647bfa830607dd4ade1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.427430459856987 -obj_loss: 1.4165437370538712 -accuracy: 0.3958 -precision: 0.37877256134352266 -recall: 0.3958 -f1: 0.3645322227875685 -mse: NA -k_selection_loss: 1.0869140625 -k_continuity_loss: 2.06865234375\n",
      "--\n",
      "---- Best Dev loss is 1.4102 at epoch 1\n",
      "-------------\n",
      "Epoch 3:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccc8427ad814fe0b942c7e0c77c4ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.182549819824802 -obj_loss: 1.129928806025511 -accuracy: 0.5122 -precision: 0.5038241688171345 -recall: 0.5122 -f1: 0.5058378612088927 -mse: NA -k_selection_loss: 8.469334735991849 -k_continuity_loss: 9.67726825301055\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c62473c6aea45e5b174038e5ab22815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3603055328130722 -obj_loss: 1.3471346825361252 -accuracy: 0.4223 -precision: 0.41066485239820094 -recall: 0.4223 -f1: 0.38033915111817274 -mse: NA -k_selection_loss: 1.45009765625 -k_continuity_loss: 2.48916015625\n",
      "--\n",
      "---- Best Dev loss is 1.3603 at epoch 3\n",
      "-------------\n",
      "Epoch 4:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2ed4b687dc4977a41ee124aa3218d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.1190289243771012 -obj_loss: 1.065672202474752 -accuracy: 0.538625 -precision: 0.5315447621888731 -recall: 0.538625 -f1: 0.5336000819293313 -mse: NA -k_selection_loss: 8.840664274373632 -k_continuity_loss: 9.787278788864233\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69680074dce145989f0caa134b6c0567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.343937376141548 -obj_loss: 1.3295686185359954 -accuracy: 0.4297 -precision: 0.41801134679387253 -recall: 0.4297 -f1: 0.4091396675407832 -mse: NA -k_selection_loss: 1.6701171875 -k_continuity_loss: 2.70673828125\n",
      "--\n",
      "---- Best Dev loss is 1.3439 at epoch 4\n",
      "-------------\n",
      "Epoch 5:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0d99a3fe95432f863c4abafc3d9b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.0573324557322605 -obj_loss: 1.0049554238653486 -accuracy: 0.5715 -precision: 0.5660816855444054 -recall: 0.5715 -f1: 0.567850771043494 -mse: NA -k_selection_loss: 8.800179584770445 -k_continuity_loss: 9.595388108757652\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5709431cd394db1acbd7d0060b1fd6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3431922376155854 -obj_loss: 1.3271587431430816 -accuracy: 0.4383 -precision: 0.42997886024660475 -recall: 0.4383 -f1: 0.40813170085941364 -mse: NA -k_selection_loss: 1.956640625 -k_continuity_loss: 3.01103515625\n",
      "--\n",
      "---- Best Dev loss is 1.3432 at epoch 5\n",
      "-------------\n",
      "Epoch 6:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d673e67d4241f0b80e87f4caafef18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.9954919587275025 -obj_loss: 0.9440665890456764 -accuracy: 0.6028 -precision: 0.5987861538289272 -recall: 0.6028 -f1: 0.600281270147063 -mse: NA -k_selection_loss: 8.59940879967562 -k_continuity_loss: 9.42513253886229\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b081ba5db8984cf9a7fe3a0fdc16c27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3035925954580307 -obj_loss: 1.287042850255966 -accuracy: 0.4553 -precision: 0.44174598444777846 -recall: 0.4553 -f1: 0.4376743300905228 -mse: NA -k_selection_loss: 2.02431640625 -k_continuity_loss: 3.10751953125\n",
      "--\n",
      "---- Best Dev loss is 1.3036 at epoch 6\n",
      "-------------\n",
      "Epoch 7:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980b9f2095a0492485cbda303417938c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.9325506979492819 -obj_loss: 0.881525541187092 -accuracy: 0.633675 -precision: 0.6311275960022406 -recall: 0.633675 -f1: 0.6321438155225793 -mse: NA -k_selection_loss: 8.617305710057543 -k_continuity_loss: 9.34330167284437\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdd5ed1f41e49ad9ad12d38b241dad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3146589428186417 -obj_loss: 1.2965563982725143 -accuracy: 0.4623 -precision: 0.45860090648088936 -recall: 0.4623 -f1: 0.45034075575490207 -mse: NA -k_selection_loss: 2.3759765625 -k_continuity_loss: 3.38291015625\n",
      "--\n",
      "---- Best Dev loss is 1.3036 at epoch 6\n",
      "-------------\n",
      "Epoch 8:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0f422b98f84af984f0f616352b754a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.8780248806734753 -obj_loss: 0.8265505201497655 -accuracy: 0.659175 -precision: 0.6570368215429787 -recall: 0.659175 -f1: 0.65788275351558 -mse: NA -k_selection_loss: 8.806262074002795 -k_continuity_loss: 9.414246152161033\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e920c4c893495da6ed0711c3dc7be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3647727757692336 -obj_loss: 1.3473452270030974 -accuracy: 0.4577 -precision: 0.4479420294962227 -recall: 0.4577 -f1: 0.4378129617823733 -mse: NA -k_selection_loss: 2.2779296875 -k_continuity_loss: 3.25771484375\n",
      "--\n",
      "---- Best Dev loss is 1.3036 at epoch 6\n",
      "-------------\n",
      "Epoch 9:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab83513f4a44de0bdbfbc2ca04e60a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.8187422619503775 -obj_loss: 0.7671925281263461 -accuracy: 0.68415 -precision: 0.6827777889396012 -recall: 0.68415 -f1: 0.6833347392794085 -mse: NA -k_selection_loss: 8.854461672959054 -k_continuity_loss: 9.42450105460586\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8fa24fc3cb48d6a86468ff805ef11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3022212237119675 -obj_loss: 1.2817735224962234 -accuracy: 0.4894 -precision: 0.48241222234753134 -recall: 0.4894 -f1: 0.4749909443931976 -mse: NA -k_selection_loss: 2.85341796875 -k_continuity_loss: 3.80419921875\n",
      "--\n",
      "---- Best Dev loss is 1.3022 at epoch 9\n",
      "-------------\n",
      "Epoch 10:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad44ff41749b45b7af272df025f9ac31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.770709046133005 -obj_loss: 0.7184112580718508 -accuracy: 0.706 -precision: 0.7046191073960522 -recall: 0.706 -f1: 0.7051488874740459 -mse: NA -k_selection_loss: 9.021989682677445 -k_continuity_loss: 9.557358674942309\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6764cd3669bb43c3adf360a9fc1783fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.320826095342636 -obj_loss: 1.3011505603790283 -accuracy: 0.4852 -precision: 0.4767757145839103 -recall: 0.4852 -f1: 0.47203448575351775 -mse: NA -k_selection_loss: 2.72412109375 -k_continuity_loss: 3.6626953125\n",
      "--\n",
      "---- Best Dev loss is 1.3022 at epoch 9\n",
      "-------------\n",
      "Epoch 11:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b0bcaa8db146e8a171fc45d991f308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.7268949693934933 -obj_loss: 0.6747489404526485 -accuracy: 0.724025 -precision: 0.7229161158594881 -recall: 0.724025 -f1: 0.7233149362178742 -mse: NA -k_selection_loss: 8.978279280814396 -k_continuity_loss: 9.531377853101985\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465467ce23cb4a97b1ea53e6eb89c036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3716538906097413 -obj_loss: 1.352220633625984 -accuracy: 0.4837 -precision: 0.4773133811806598 -recall: 0.4837 -f1: 0.4625689630060535 -mse: NA -k_selection_loss: 2.67509765625 -k_continuity_loss: 3.619140625\n",
      "--\n",
      "---- Best Dev loss is 1.3022 at epoch 9\n",
      "-------------\n",
      "Epoch 12:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0f580dbc514669a5e896d5042527da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.6889667419870947 -obj_loss: 0.6372079775211917 -accuracy: 0.739425 -precision: 0.7382837988810009 -recall: 0.739425 -f1: 0.738688144417694 -mse: NA -k_selection_loss: 9.019929803860416 -k_continuity_loss: 9.449760485606589\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56991a3de454654a72ea5973331e7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3017937004566194 -obj_loss: 1.2794080674648285 -accuracy: 0.5121 -precision: 0.5049631357339824 -recall: 0.5121 -f1: 0.5041218472379583 -mse: NA -k_selection_loss: 3.3220703125 -k_continuity_loss: 4.144921875\n",
      "--\n",
      "---- Best Dev loss is 1.3018 at epoch 12\n",
      "-------------\n",
      "Epoch 13:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2584e6e4de4027b277eb4c6a4e8d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.6537174077550317 -obj_loss: 0.6019744983144627 -accuracy: 0.75565 -precision: 0.7550125709328027 -recall: 0.75565 -f1: 0.7552458074881585 -mse: NA -k_selection_loss: 9.042353447835158 -k_continuity_loss: 9.444346822750797\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98949a23a6645f2a6addec994af90a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.336856210231781 -obj_loss: 1.3126942962408066 -accuracy: 0.5249 -precision: 0.5239784753953408 -recall: 0.5249 -f1: 0.5072094049114627 -mse: NA -k_selection_loss: 3.5533203125 -k_continuity_loss: 4.47705078125\n",
      "--\n",
      "---- Best Dev loss is 1.3018 at epoch 12\n",
      "-------------\n",
      "Epoch 14:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675c59ded27f430998f326c6457342ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.6121916431150619 -obj_loss: 0.5603353569082393 -accuracy: 0.771375 -precision: 0.7707039188344071 -recall: 0.771375 -f1: 0.7708887573332898 -mse: NA -k_selection_loss: 9.065742146437335 -k_continuity_loss: 9.464683022468712\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1277a2900d4643efa1309d0c100d3193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.2930368021130563 -obj_loss: 1.2682506799697877 -accuracy: 0.5375 -precision: 0.530828182915489 -recall: 0.5375 -f1: 0.528781080720964 -mse: NA -k_selection_loss: 3.7509765625 -k_continuity_loss: 4.58212890625\n",
      "--\n",
      "---- Best Dev loss is 1.2930 at epoch 14\n",
      "-------------\n",
      "Epoch 15:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e3e6579d5d4504bcb5e6b6a18b603a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.5813796258276436 -obj_loss: 0.5288666646192028 -accuracy: 0.7854 -precision: 0.78477819849882 -recall: 0.7854 -f1: 0.7849771869972656 -mse: NA -k_selection_loss: 9.188118558021108 -k_continuity_loss: 9.583780792868062\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05da914c96e4314ba34754edcafe384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3360157579183578 -obj_loss: 1.3118525624275208 -accuracy: 0.5351 -precision: 0.5304313186246798 -recall: 0.5351 -f1: 0.5290534473580111 -mse: NA -k_selection_loss: 3.5353515625 -k_continuity_loss: 4.4791015625\n",
      "--\n",
      "---- Best Dev loss is 1.2930 at epoch 14\n",
      "-------------\n",
      "Epoch 16:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf90571bf6b4395906bff45dd281f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.5583837846661829 -obj_loss: 0.505941416427588 -accuracy: 0.796775 -precision: 0.7963834559995233 -recall: 0.796775 -f1: 0.7964850457040819 -mse: NA -k_selection_loss: 9.147358122904588 -k_continuity_loss: 9.57373795843428\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e87dc8896c46e0b01bead3e392cabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3046487987041473 -obj_loss: 1.2794938296079637 -accuracy: 0.5384 -precision: 0.533728976039814 -recall: 0.5384 -f1: 0.5320842095025089 -mse: NA -k_selection_loss: 3.8431640625 -k_continuity_loss: 4.6466796875\n",
      "--\n",
      "---- Best Dev loss is 1.2930 at epoch 14\n",
      "-------------\n",
      "Epoch 17:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a406a26f40044d38540d4a141d53950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.5276646156599567 -obj_loss: 0.4755971179266644 -accuracy: 0.80905 -precision: 0.8086851777086328 -recall: 0.80905 -f1: 0.8087581615008012 -mse: NA -k_selection_loss: 9.180311002549093 -k_continuity_loss: 9.495468242912535\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8209dddc9824477dbf00cb290b964109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.2886425256729126 -obj_loss: 1.2604636013507844 -accuracy: 0.5736 -precision: 0.5718158848577225 -recall: 0.5736 -f1: 0.5647967036235694 -mse: NA -k_selection_loss: 4.2865234375 -k_continuity_loss: 5.20712890625\n",
      "--\n",
      "---- Best Dev loss is 1.2886 at epoch 17\n",
      "-------------\n",
      "Epoch 18:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6224c795844515a62780b593c3a9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.5001913174322457 -obj_loss: 0.44764456532563374 -accuracy: 0.820075 -precision: 0.8198530944552743 -recall: 0.820075 -f1: 0.8198399598547816 -mse: NA -k_selection_loss: 9.26678012434844 -k_continuity_loss: 9.582672781245723\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24d368b66a94ec3837bec10dc72bad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.4067144215106964 -obj_loss: 1.380179750919342 -accuracy: 0.5551 -precision: 0.5499673077724964 -recall: 0.5551 -f1: 0.5474458976363168 -mse: NA -k_selection_loss: 4.0419921875 -k_continuity_loss: 4.902734375\n",
      "--\n",
      "---- Best Dev loss is 1.2886 at epoch 17\n",
      "-------------\n",
      "Epoch 19:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49d9bdca703472db9d9e0dd8995c3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.4867874702830223 -obj_loss: 0.4338845863084125 -accuracy: 0.830425 -precision: 0.830176141628456 -recall: 0.830425 -f1: 0.830193111061886 -mse: NA -k_selection_loss: 9.297609213810818 -k_continuity_loss: 9.650815696473334\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da987eafcfd34889b1b45dd1f6d7c90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3979893565177917 -obj_loss: 1.3712874472141265 -accuracy: 0.5554 -precision: 0.5544352143746394 -recall: 0.5554 -f1: 0.543731403833777 -mse: NA -k_selection_loss: 4.08837890625 -k_continuity_loss: 4.93154296875\n",
      "--\n",
      "---- Best Dev loss is 1.2886 at epoch 17\n",
      "-------------\n",
      "Epoch 20:\n",
      "\n",
      "Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4ac8bfaa35422e9189e8072e610603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 0.46808143273280683 -obj_loss: 0.4150926058839081 -accuracy: 0.836675 -precision: 0.8364134764379801 -recall: 0.836675 -f1: 0.8364744974413115 -mse: NA -k_selection_loss: 9.30441295720969 -k_continuity_loss: 9.667324126905696\n",
      "--\n",
      "Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d399ddb99e4abfb756335d2850de82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " cross_entropy -  -loss: 1.3142448127269746 -obj_loss: 1.2844706356525422 -accuracy: 0.5909 -precision: 0.5945970391032714 -recall: 0.5909 -f1: 0.5831586922369371 -mse: NA -k_selection_loss: 4.67041015625 -k_continuity_loss: 5.48779296875\n",
      "--\n",
      "---- Best Dev loss is 1.2886 at epoch 17\n"
     ]
    }
   ],
   "source": [
    "epoch_stats, model, gen = train_model(train_data, dev_data, model, gen, args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict['selection_lambda']=0.04\n",
    "args_dict['continuity_lambda']=3 * args_dict['selection_lambda']\n",
    "args_dict['batch_size'] = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_stats, model, gen = train_model(train_data, dev_data, model, gen, args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore model to best dev performance\n",
    "if os.path.exists(args_dict['model_path']):\n",
    "    model.cpu()\n",
    "    model = torch.load(args_dict['model_path'])\n",
    "    gen.cpu()\n",
    "    gen = torch.load(get_gen_path(args_dict['model_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save train/dev results to logs/demo_run.results\n"
     ]
    }
   ],
   "source": [
    "args_dict['epoch_stats'] = epoch_stats\n",
    "save_path = args_dict['results_path']\n",
    "print(\"Save train/dev results to\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(args_dict, open(save_path,'wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "gen = gen.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict['batch_size'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args_dict['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=args_dict['num_workers'],\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = True\n",
    "# train_model = False\n",
    "key_prefix = 'test'\n",
    "data_iter = test_loader.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding_layer): Embedding(400001, 300)\n",
       "  (embedding_fc): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (embedding_bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (cnn): CNN(\n",
       "    (layer_0_conv_3): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (layer_0_conv_4): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (layer_0_conv_5): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.2)\n",
       "  (hidden): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.eval()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_indx, y, text = b['x'].cuda(), b['y'].cuda(), b['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, z = gen(x_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_ _ incredibly impressed with _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ excellent service was great and _ _ _ awesome even _ _ _ _ _ _ somewhat questionable _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ awesome you _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ awesome very knowledgable _ _ _ _ _ _ _',\n",
       " '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ rude gestures _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rationales(mask, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we were incredibly impressed with our first embarrassed to admit experience at binks we have been talking about going for a long time and finally tried them for sunday brunch the food was excellent service was great and the setting is awesome even though binks is located in a somewhat questionable neighborhood and this is coming from a central phoenix resident on a semi busy street the patio is awesome you don t really notice the surroundings even while playing a game of croquet which we did the server was awesome very knowledgable and even got a chef to open',\n",
       " 'i came to place an order for a birthday cake the open sign was on so i proceed to open the door the few people that were inside started making some gestures i didn t understand then a man came closer and with very rude gestures pointed a some small later that said closed on wednesday nit would only take him a second to open the door and say we are close today i apologize for the inconvenience ni simply drove two blocks down and went to roly s bakery where they happily helped me nthere are many restaurants in']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit, _ = model(x_indx, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_softmax = F.softmax(logit, dim=-1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(batch_softmax, 1)[1].view(y.size()).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_ _ is amazing me _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ unbelievably horrible _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       " '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ always glad _ _ _ _ _ _ excellent instructor _ upbeat _ _ _ _ _ _ _ encouragement _ _ _ _ _ _ _ _ pretty neat and super easy _ _ _ _ _ _ _ _ _ _ _ _ _ _ _']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rationales(mask, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the food is amazing me and my wife have been clients since we where children recently the service has been unbelievably horrible last night we visited the restaurant and there was no one at the front door to sit us down we waited with another 3 parties for like 8 minutes after going into the back of the restaurant all the employees where sitting behind the bar counting their tips it only went down hill from there i had to',\n",
       " 'as a novice to pilates i was a bit intimidated by the reformer accordingly my first few classes were brutal but in the weeks since i ve become much stronger and am always glad when i attend christina is an excellent instructor friendly upbeat and quick to make corrections and provide encouragement n nthe online scheduling system at imx is pretty neat and super easy to use class sizes are small however i almost always get into the class i']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
